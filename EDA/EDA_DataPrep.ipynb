{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "EDA_DataPrep.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ0QBTTmxsDu"
      },
      "source": [
        "# Análisis Exploratorio y Preparación de Datos\n",
        "## TC 2031 Ciencia de Datos\n",
        "## @etnarojas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVwJO_hYxsD3"
      },
      "source": [
        "- Objetivo:\n",
        "   \n",
        "    - Mostrar lo que se hace cuando se hace un análisis exploratorio de los datos y se preparan para poder usarlos para hacer análisis o modelos.\n",
        "    - En proyectos reales entre el 50% y 80% del tiempo se emplea en tareas de preparación de los datos para empezar a modelar\n",
        "    \n",
        "  \n",
        "- Librerías de Python usadas:\n",
        "    - pandas\n",
        "    - Matplotlib\n",
        "    - Numpy\n",
        "   \n",
        "\n",
        "Dataset para el ejemplo tomado de : https://archive.ics.uci.edu/ml/datasets/Adult"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGIHS59jxsD4"
      },
      "source": [
        "1. Limpieza de Datos\n",
        "    1. Manejo de diferentes tipos de datos \n",
        "    2. Manejo de datos faltantes\n",
        "2. Exploración de los Datos\n",
        "    1. Descripción de los datos\n",
        "    2. Gráficas de las distribuciones de los Datos\n",
        "    3. Detección de valores atípicos\n",
        "3. Creando los Datos para hacer el Modelo\n",
        "    1. Relaciones entre variables\n",
        "    2. Selección de variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9NhFDlnxsD4"
      },
      "source": [
        "## Modelo\n",
        "\n",
        "Un modelo que dados los atributos sobre una persona haga una predicción para saber s si su ingreso es <= 50000 o > 50000 Dlls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1IFptTnxsD4"
      },
      "source": [
        "## Datos\n",
        "### Una descripción del tipo de dato y que representa \n",
        "\n",
        "- age: continuous.\n",
        "- workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
        "- fnlwgt: continuous.represents final weight, which is the number of units in the target population that the responding unit represents\n",
        "- education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
        "- education-num: continuous.\n",
        "- marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
        "- occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
        "- relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
        "- race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
        "- sex: Female, Male.\n",
        "- capital-gain: continuous.\n",
        "- capital-loss: continuous.\n",
        "- hours-per-week: continuous.\n",
        "- native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.7\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoCh4vKAxsD5"
      },
      "source": [
        "# Importando librerías y datos\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('adult.csv',na_values=['#NAME?'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjmhKCu0xsD6"
      },
      "source": [
        "print(df.head(5))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq-2IjiJxsD6"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvnjaOSlxsD7"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7QFMLzXxsD8"
      },
      "source": [
        "type(df['education'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGOEmfbBxsD8"
      },
      "source": [
        "# Ver la variable 'income' el tipo y cuantos hay de cada tipo\n",
        "print(df['income'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4EBZR9rxsD9"
      },
      "source": [
        "# Asignar el valor de 0 Si income <=50K y de 1 Si 1 income >50K\n",
        "df['income'] = [0 if x == '<=50K' else 1 for x in df['income']]\n",
        "\n",
        "# Crear dos DataFrames X con variables indpendientes o features y uno y con variable dependiente , la que vamos a predecir\n",
        "X = df.drop('income', 1)\n",
        "y = df.income"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7YsolWcxsD9"
      },
      "source": [
        "print(X.head(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSEl_cDDxsD9"
      },
      "source": [
        "print(y.head(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MS0pMdkxsD9"
      },
      "source": [
        "## 1. Limpieza de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-ZhXX_WxsD-"
      },
      "source": [
        "### A. Manejo de diferentes tipos de datos \n",
        "\n",
        "- Hay tres tipos principales de datos:\n",
        "    - Cuantitativo, Numérico: ingreso, edad\n",
        "    - Cualitativo, Categórico:  género, nacionalidad\n",
        "    - Cualitativo, Categórico Ordinal: bajo medio alto\n",
        "    \n",
        "- Los modelos sólo pueden manejar variables cuantitativas numéricas\n",
        "- Se deben convertir las variables cualitativas ó categóricas en variables numéricas\n",
        "    - Crear variables extra\n",
        "    - Transformar una variable cualitativa o categórica en un conjunto de variables extra, cada una representando una categoría única\n",
        "    - En el conjunto de variables extra, 1 indica que la observación pertenece a esa categoría\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mciru8oNxsD-"
      },
      "source": [
        "# Education es una variable cualitativa\n",
        "print(X['education'].head(20))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJHYFoXtxsD-"
      },
      "source": [
        "# Ver las caterorías de las variables categoricas o cualitativas\n",
        "\n",
        "for col_name in X.columns:\n",
        "    if X[col_name].dtypes == 'object':\n",
        "        unique_cat = len(X[col_name].unique())\n",
        "        print('Variable ''{col_name} tiene {unique_cat} categorías'.format(col_name=col_name, unique_cat=unique_cat))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK2MHuM5xsD_"
      },
      "source": [
        "# Use get_dummies de pandas para crear las variables dummies extra para representar a las variable cualitativa como numéricas\n",
        "# Otra opción es usar  OneHotEncoder de la librería:  sci-kit learn\n",
        "print(pd.get_dummies(X['education']).head(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsznu4uBxsD_"
      },
      "source": [
        "# Para ver las categorías de 'native_country' y vemos que es dominante la de Unites States\n",
        "print(X['native_country'].value_counts().sort_values(ascending=False).head(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY979EvoxsD_"
      },
      "source": [
        "# Podemos hacer que la baja frecuencia de las otras queden clasificadas como \"Other\"\n",
        "X['native_country'] = ['United-States ' if x == 'United-States' else 'Other' for x in X['native_country']]\n",
        "\n",
        "print(X['native_country'].value_counts().sort_values(ascending=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i7XAbFDxsD_"
      },
      "source": [
        "# Crear toda la lista de variables categóricas para transformarlas a numéricas\n",
        "todummy_list = ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGsHAczSxsEA"
      },
      "source": [
        "# Función para llamar get dummies c\n",
        "def dummy_df(df, todummy_list):\n",
        "    for x in todummy_list:\n",
        "        dummies = pd.get_dummies(df[x], prefix=x, dummy_na=False)\n",
        "        df = df.drop(x, 1)\n",
        "        df = pd.concat([df, dummies], axis=1)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DEaZv89xsEA"
      },
      "source": [
        "X = dummy_df(X, todummy_list)\n",
        "print(X.head(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aFIPYc4xsEA"
      },
      "source": [
        "### B. Manejo de datos faltantes\n",
        "\n",
        "- Los modelos no pueden manejar datos faltantes\n",
        "\n",
        "\n",
        "- La solución más simple\n",
        "    - Eliminar observaciones / características que tienen datos faltantes\n",
        "    \n",
        "\n",
        "- Pero, eliminar datos faltantes puede presentar muchos problemas\n",
        "    - Datos faltantes están distribuidos al azar y son muchos : posiblemente pierda muchos de sus datos\n",
        "    - Datos faltantes no están distribuidos al azar y son muchos : además de perder datos, también está introduciendo posibles sesgos\n",
        "\n",
        "\n",
        "- Una solución alternativa es utilizar la imputación.\n",
        "    - Reemplace el valor faltante con otro valor\n",
        "    - Estrategias: media, mediana, valor de frecuencia más alta de una variable dada\n",
        "    \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jerkiULxsEA"
      },
      "source": [
        "# Cuantos son datos faltantes?\n",
        "X.isnull().sum().sort_values(ascending=False).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etbAs-6lxsEB"
      },
      "source": [
        "# Para Imputar / Reemplazar los valores faltantes se usa Imputer de sklearn.preprocessing\n",
        "from sklearn.preprocessing import Imputer\n",
        "\n",
        "imp = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
        "imp.fit(X)\n",
        "X = pd.DataFrame(data=imp.transform(X) , columns=X.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXFZgXiUxsEB"
      },
      "source": [
        "#Ahora volvemos a verificar como los nulos se han reemplazado con un valor\n",
        "X.isnull().sum().sort_values(ascending=False).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv2Hb7rWxsEB"
      },
      "source": [
        "## 2. Exploration de los Datos\n",
        "- Entender el problema y los datos es extremadamente importante para construir modelos\n",
        "- Se hace lo que se conoce como Análisis Exploratorio de los Datos para explorar sus datos entenderlos y tomar mejores decisiones al modelar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm6mV03KxsEB"
      },
      "source": [
        "### A.Descripción de los Datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "806MSZ__xsEB"
      },
      "source": [
        "X.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_476qReuxsEC"
      },
      "source": [
        "### B.Gráficas de las distribuciones de los Datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWkxuKYdxsEC"
      },
      "source": [
        "# Use pyplot de matplotlib para hacer histograms\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_histogram(x):\n",
        "    plt.hist(x, color='gray', alpha=0.5)\n",
        "    plt.title('Histogram of ''{var_name}'.format(var_name=x.name))\n",
        "    plt.xlabel('Value')\n",
        "    plt.ylabel('Frecuency')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pomXV3emxsEC"
      },
      "source": [
        "plot_histogram(X['age'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIhmHH9hxsEC"
      },
      "source": [
        "for col_name in X.columns:\n",
        "    plot_histogram(X[col_name])\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUeZrLgoxsED"
      },
      "source": [
        "### C. Detección de valores atípicos\n",
        "\n",
        "- Un valor atípico es una observación que se desvía drásticamente de otras observaciones en un conjunto de datos\n",
        "\n",
        "\n",
        "- Ocurrencia:\n",
        "    - Natural, por ejemplo Ingresos de Millonarios\n",
        "    - Error, por ejemplo peso humano de 5,00 kg. debido al error de escritura adicional 0\n",
        "\n",
        "- ¿Por qué son problemáticos?\n",
        "    - Si ocurren naturalmente\n",
        "        - No necesariamente problemático\n",
        "        - Pero pueden sesgar su modelo\n",
        "    - Error \n",
        "        - Indicativo de problemas de calidad de datos.\n",
        "        - Tratar de la misma manera como un valor faltante, es decir, usar la imputación\n",
        "   \n",
        "   \n",
        "- ¿Cómo se detectan?\n",
        "    - Visualizaciones Box Plot\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plOJcrsPxsED"
      },
      "source": [
        " ### Detección de valores atípicos - Usando Box Plots\n",
        "- Identifica valores extremos en los datos.\n",
        "- Los valores atípicos se definen como:\n",
        "    - Valores inferiores a Q1-1.5 (Q3-Q1) o superiores a Q3 + 1.5 (Q3-Q1)\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm5o0dA7xsED"
      },
      "source": [
        "def find_outliers_tukey(x):\n",
        "    q1 = np.percentile(x, 25)\n",
        "    q3 = np.percentile(x, 75)\n",
        "    iqr = q3-q1 \n",
        "    floor = q1 - 1.5*iqr\n",
        "    ceiling = q3 + 1.5*iqr\n",
        "    outlier_indices = list(x.index[(x < floor)|(x > ceiling)])\n",
        "    outlier_values = list(x[outlier_indices])\n",
        "\n",
        "    return outlier_indices, outlier_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "EDmxPl7PxsED"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(filename='outliers_boxplot.jpg')\n",
        "# Imagine taken from: \n",
        "# http://datapigtechnologies.com/blog/index.php/highlighting-outliers-in-your-data-with-the-tukey-method/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9zfD47KxsEE"
      },
      "source": [
        "tukey_indices, tukey_values = find_outliers_tukey(X['age'])\n",
        "print(np.sort(tukey_values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnGhFtblxsEF"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(filename='outliers.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcRv-2pFxsEF"
      },
      "source": [
        "## 3. Creando los Datos para hacer el Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ybr-gAmRxsEF"
      },
      "source": [
        "### A. Relaciones entre variables\n",
        "\n",
        "- La variables independientes pueden estar correlacionadas y en ocasiones hay modelos como las regersiones que no permiten isar variables correlacionadas porque se afecta el resultado.\n",
        "\n",
        "- Fecha de Nacimiento y Edad tienen una relación entre ellas y hay que decidir cual usar.\n",
        "- No siempre es evidente esta relación entre las variables\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWkWse9exsEF"
      },
      "source": [
        "# Puedes analizar una matriz de correlaciones de todas las variables\n",
        "X.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFSX90dWxsEG"
      },
      "source": [
        "### B. Selección de Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k6M2in0xsEG"
      },
      "source": [
        "# Al agregar variable dummies por variables categóricas se incrementó el número de variables\n",
        "print(df.shape)\n",
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czBrQS8VxsEG"
      },
      "source": [
        "# Usar train_test_split in sklearn.cross_validation para partir los datos en dos set de enternamiento y de testeo\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.cross_validation import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.70, random_state=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4rnXNGZxsEH"
      },
      "source": [
        "\n",
        "# Usar el  método feature selection para seleccionar las varuables más significativas\n",
        "import sklearn.feature_selection\n",
        "\n",
        "\n",
        "select = sklearn.feature_selection.SelectKBest(k=20)\n",
        "selected_features = select.fit(X_train, y_train)\n",
        "indices_selected = selected_features.get_support(indices=True)\n",
        "colnames_selected = [X.columns[i] for i in indices_selected]\n",
        "\n",
        "X_train_selected = X_train[colnames_selected]\n",
        "X_test_selected = X_test[colnames_selected]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMDLmSpLxsEH"
      },
      "source": [
        "print(colnames_selected)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7PGmlJ9xsEH"
      },
      "source": [
        "print(len(colnames_selected))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}